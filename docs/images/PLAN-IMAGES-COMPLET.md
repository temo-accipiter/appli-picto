# ğŸš€ PLAN COMPLET - REFONTE SYSTÃˆME D'IMAGES APPLI-PICTO

## ğŸ“‹ Vue d'ensemble

**Objectif :** Moderniser le traitement des images avec WebP, dÃ©duplication, cache optimisÃ©, et support HEIC.

**Architecture :**

- **Images privÃ©es (tÃ¢ches/rÃ©compenses utilisateurs)** â†’ Supabase Storage (bucket privÃ© + signed URLs)
- **Images publiques (pictos partagÃ©s - rare)** â†’ Cloudinary CDN (Ã  implÃ©menter ultÃ©rieurement)

**StratÃ©gie d'implÃ©mentation :**

1. **PHASE A** : SystÃ¨me complet pour images privÃ©es Supabase Storage (PRIORITÃ‰)
2. **PHASE B** : Extension Cloudinary pour images publiques (APRÃˆS Phase A stabilisÃ©e)

**Temps total estimÃ© :** 25-30 heures

---

# ğŸ“¦ PHASE A : IMAGES PRIVÃ‰ES SUPABASE STORAGE

**PrioritÃ© :** ğŸ”´ **CRITIQUE** - Ã€ faire en premier
**Temps estimÃ© :** 18-22 heures
**Objectif :** SystÃ¨me complet fonctionnel pour 99% des cas d'usage (images utilisateurs privÃ©es)

---

## Ã‰TAPE A1 : PRÃ‰PARATION BASE DE DONNÃ‰ES (2-3h)

### A1.1 - Migration `user_assets` : Nouveaux champs

**ğŸ¯ Objectif :** Enrichir la table pour versioning, dÃ©duplication, monitoring

**ğŸ“ Action :**

**CrÃ©er :** `supabase/migrations/20251023000001_enhance_user_assets.sql`

```sql
-- Migration : Enrichissement table user_assets pour systÃ¨me moderne
-- Date : 2025-10-23
-- Auteur : Claude Code

-- Ajout colonnes modernes
ALTER TABLE public.user_assets
  ADD COLUMN IF NOT EXISTS version INTEGER DEFAULT 1 NOT NULL,
  ADD COLUMN IF NOT EXISTS sha256_hash TEXT,
  ADD COLUMN IF NOT EXISTS width INTEGER,
  ADD COLUMN IF NOT EXISTS height INTEGER,
  ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMPTZ,
  ADD COLUMN IF NOT EXISTS migrated_at TIMESTAMPTZ;

-- Note : cloudinary_* seront ajoutÃ©s en Phase B

-- Index pour performance
CREATE INDEX IF NOT EXISTS idx_user_assets_sha256
  ON public.user_assets(sha256_hash)
  WHERE sha256_hash IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_user_assets_version
  ON public.user_assets(user_id, asset_type, version);

CREATE INDEX IF NOT EXISTS idx_user_assets_deleted
  ON public.user_assets(deleted_at)
  WHERE deleted_at IS NOT NULL;

-- Contrainte unicitÃ© hash (dÃ©duplication)
CREATE UNIQUE INDEX IF NOT EXISTS idx_user_assets_unique_hash
  ON public.user_assets(user_id, sha256_hash)
  WHERE sha256_hash IS NOT NULL AND deleted_at IS NULL;

-- Commentaires documentation
COMMENT ON COLUMN public.user_assets.version IS 'Version de l''image (incrÃ©mentÃ© Ã  chaque remplacement)';
COMMENT ON COLUMN public.user_assets.sha256_hash IS 'Hash SHA-256 pour dÃ©duplication (Ã©vite uploads identiques)';
COMMENT ON COLUMN public.user_assets.width IS 'Largeur image en pixels (extrait aprÃ¨s upload)';
COMMENT ON COLUMN public.user_assets.height IS 'Hauteur image en pixels (extrait aprÃ¨s upload)';
COMMENT ON COLUMN public.user_assets.deleted_at IS 'Soft delete timestamp (NULL = actif, NOT NULL = supprimÃ©)';
COMMENT ON COLUMN public.user_assets.migrated_at IS 'Date migration vers nouveau systÃ¨me (NULL = ancien systÃ¨me)';
```

**Commandes :**

```bash
# Appliquer migration
npx supabase db push

# Mettre Ã  jour schema.sql
yarn db:dump

# VÃ©rifier
npx supabase db diff
```

**âœ… RÃ©sultat attendu :**

- Table `user_assets` enrichie avec 6 nouvelles colonnes
- Index crÃ©Ã©s pour performance
- Contrainte unicitÃ© hash active

---

### A1.2 - Fonction RPC `check_duplicate_image()`

**ğŸ¯ Objectif :** DÃ©duplication avant upload (Ã©viter uploads identiques)

**ğŸ“ Action :**

**CrÃ©er :** `supabase/migrations/20251023000002_add_check_duplicate_image.sql`

```sql
-- Fonction : VÃ©rifier si un hash d'image existe dÃ©jÃ 
-- Usage : DÃ©duplication avant upload (Ã©conomie storage)

CREATE OR REPLACE FUNCTION public.check_duplicate_image(
  p_user_id UUID,
  p_sha256_hash TEXT
)
RETURNS JSONB
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path TO 'public'
AS $$
DECLARE
  v_existing RECORD;
BEGIN
  -- VÃ©rification permission (self ou admin)
  PERFORM public.assert_self_or_admin(p_user_id);

  -- Chercher hash existant (non supprimÃ©)
  SELECT id, file_path, width, height, version
  INTO v_existing
  FROM public.user_assets
  WHERE user_id = p_user_id
    AND sha256_hash = p_sha256_hash
    AND deleted_at IS NULL
  LIMIT 1;

  IF v_existing.id IS NOT NULL THEN
    -- Hash existe dÃ©jÃ  â†’ retourner infos asset
    RETURN jsonb_build_object(
      'exists', true,
      'asset_id', v_existing.id,
      'file_path', v_existing.file_path,
      'width', v_existing.width,
      'height', v_existing.height,
      'version', v_existing.version
    );
  ELSE
    -- Hash nouveau â†’ autoriser upload
    RETURN jsonb_build_object('exists', false);
  END IF;
END;
$$;

-- Permissions
GRANT EXECUTE ON FUNCTION public.check_duplicate_image(UUID, TEXT) TO authenticated;

-- Commentaire
COMMENT ON FUNCTION public.check_duplicate_image IS
  'VÃ©rifie si un hash SHA-256 existe dÃ©jÃ  pour un utilisateur (dÃ©duplication)';
```

**Commandes :**

```bash
npx supabase db push
yarn db:dump
```

**âœ… RÃ©sultat attendu :**

- Fonction RPC `check_duplicate_image()` disponible
- Accessible depuis client Supabase JS

---

### A1.3 - Table `image_metrics` (monitoring)

**ğŸ¯ Objectif :** Tracker uploads, compression ratio, erreurs (analytics)

**ğŸ“ Action :**

**CrÃ©er :** `supabase/migrations/20251023000003_add_image_metrics.sql`

```sql
-- Table : MÃ©triques uploads images (monitoring & analytics)

CREATE TABLE IF NOT EXISTS public.image_metrics (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  asset_type TEXT NOT NULL CHECK (asset_type IN ('task_image', 'reward_image')),

  -- MÃ©triques compression
  original_size BIGINT NOT NULL CHECK (original_size >= 0),
  compressed_size BIGINT NOT NULL CHECK (compressed_size >= 0),
  compression_ratio NUMERIC(5,2) GENERATED ALWAYS AS (
    CASE
      WHEN original_size > 0 THEN
        ROUND((1 - (compressed_size::numeric / original_size::numeric)) * 100, 2)
      ELSE 0
    END
  ) STORED,

  -- Performance (millisecondes)
  conversion_ms INTEGER CHECK (conversion_ms >= 0),
  upload_ms INTEGER CHECK (upload_ms >= 0),

  -- RÃ©sultat upload
  result TEXT NOT NULL CHECK (result IN ('success', 'failed', 'fallback_original')),
  error_message TEXT,

  -- Contexte technique
  mime_type_original TEXT,
  mime_type_final TEXT,
  conversion_method TEXT CHECK (
    conversion_method IN ('client_webp', 'heic_to_jpeg_then_webp', 'none', 'svg_unchanged')
  ),

  created_at TIMESTAMPTZ DEFAULT NOW() NOT NULL
);

-- Index pour analytics
CREATE INDEX idx_image_metrics_user ON public.image_metrics(user_id);
CREATE INDEX idx_image_metrics_result ON public.image_metrics(result);
CREATE INDEX idx_image_metrics_date ON public.image_metrics(created_at DESC);
CREATE INDEX idx_image_metrics_asset_type ON public.image_metrics(asset_type);

-- RLS
ALTER TABLE public.image_metrics ENABLE ROW LEVEL SECURITY;

-- Politique : users voient leurs propres metrics
CREATE POLICY "Users can view own metrics"
  ON public.image_metrics
  FOR SELECT
  USING (auth.uid() = user_id);

-- Politique : users peuvent insÃ©rer leurs propres metrics
CREATE POLICY "Users can insert own metrics"
  ON public.image_metrics
  FOR INSERT
  WITH CHECK (auth.uid() = user_id);

-- Politique : admins voient toutes les metrics
CREATE POLICY "Admins can view all metrics"
  ON public.image_metrics
  FOR SELECT
  USING (public.is_admin());

-- Permissions
GRANT SELECT, INSERT ON public.image_metrics TO authenticated;

-- Commentaire
COMMENT ON TABLE public.image_metrics IS
  'MÃ©triques uploads images : compression ratio, performance, erreurs (analytics)';
```

**Fonction RPC analytics (bonus admin) :**

```sql
-- Fonction : Statistiques globales uploads (7 derniers jours)
CREATE OR REPLACE FUNCTION public.get_image_analytics_summary()
RETURNS JSONB
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  -- Admins uniquement
  IF NOT public.is_admin() THEN
    RAISE EXCEPTION 'Permission denied: admins only' USING ERRCODE = '42501';
  END IF;

  RETURN (
    SELECT jsonb_build_object(
      'period_days', 7,
      'total_uploads', COUNT(*),
      'success_count', COUNT(*) FILTER (WHERE result = 'success'),
      'failed_count', COUNT(*) FILTER (WHERE result = 'failed'),
      'avg_compression_ratio', ROUND(AVG(compression_ratio), 2),
      'avg_conversion_ms', ROUND(AVG(conversion_ms), 0),
      'avg_upload_ms', ROUND(AVG(upload_ms), 0),
      'total_storage_saved_mb', ROUND(SUM(original_size - compressed_size) / 1048576.0, 2)
    )
    FROM public.image_metrics
    WHERE created_at > NOW() - INTERVAL '7 days'
  );
END;
$$;

GRANT EXECUTE ON FUNCTION public.get_image_analytics_summary() TO authenticated;

COMMENT ON FUNCTION public.get_image_analytics_summary IS
  'Statistiques uploads 7 derniers jours (admins uniquement)';
```

**Commandes :**

```bash
npx supabase db push
yarn db:dump
```

**âœ… RÃ©sultat attendu :**

- Table `image_metrics` crÃ©Ã©e
- Fonction analytics admin disponible
- RLS configurÃ©e

---

## Ã‰TAPE A2 : UTILITAIRES FRONTEND - CONVERSION & VALIDATION (3-4h)

### A2.1 - Configuration globale mise Ã  jour

**ğŸ¯ Objectif :** Nouvelles constantes (20 KB, 192px, TTL 24h)

**ğŸ“ Action :**

**Modifier :** `src/utils/images/config.js`

```javascript
// src/utils/images/config.js
// Configuration globale images (validation, compression, storage)

// Formats MIME autorisÃ©s
export const ALLOWED_MIME_TYPES = [
  'image/png',
  'image/jpeg',
  'image/jpg', // NormalisÃ© en image/jpeg automatiquement
  'image/webp',
  'image/svg+xml',
  'image/heic', // ğŸ†• Support iPhone (iOS 11+)
  'image/heif', // ğŸ†• Variante HEIF
]

// Limites taille fichiers
export const MAX_UPLOAD_BYTES = 10 * 1024 * 1024 // 10 Mo (hard limit serveur)
export const TARGET_MAX_UI_SIZE_KB = 20 // ğŸ†• 20 Ko (au lieu de 100 Ko)
export const FALLBACK_MAX_UI_SIZE_KB = 30 // ğŸ†• Fallback si 20 Ko impossible

// Dimensions cibles (mobile-first TSA)
export const TARGET_DIMENSION = 192 // ğŸ†• 192Ã—192px (au lieu de 256px)

// Buckets Supabase Storage
export const PRIVATE_BUCKET = 'images' // Images privÃ©es utilisateurs
export const DEMO_PUBLIC_BUCKET = 'demo-images' // Assets dÃ©mo (admin only)

// Signed URL TTL (compromise cache CDN vs sÃ©curitÃ©)
export const SIGNED_URL_TTL_SECONDS = 24 * 60 * 60 // ğŸ†• 24h (au lieu de 6h)

// Note : Cloudinary config sera ajoutÃ© en Phase B
```

**âœ… RÃ©sultat attendu :**

- Config mise Ã  jour avec nouvelles limites
- Support HEIC ajoutÃ©
- TTL 24h pour meilleur cache CDN

---

### A2.2 - Support HEIC (iPhone)

**ğŸ¯ Objectif :** Convertir HEIC â†’ JPEG avant WebP (dÃ©bloquer 70% utilisateurs iOS)

**ğŸ“ Action :**

**Installer dÃ©pendance :**

```bash
yarn add heic2any
```

**CrÃ©er :** `src/utils/images/heicConverter.js`

```javascript
// src/utils/images/heicConverter.js
// Conversion HEIC (iPhone) â†’ JPEG

import heic2any from 'heic2any'

/**
 * Convertit HEIC (iPhone) en JPEG
 * @param {File} file - Fichier HEIC
 * @returns {Promise<File>} - Fichier JPEG converti
 */
export async function convertHEICtoJPEG(file) {
  if (!isHEIC(file)) {
    return file // Pas HEIC â†’ retour tel quel
  }

  try {
    console.log('ğŸ”„ Conversion HEIC â†’ JPEG...')

    const convertedBlob = await heic2any({
      blob: file,
      toType: 'image/jpeg',
      quality: 0.95, // Haute qualitÃ© (compression WebP aprÃ¨s)
    })

    // GÃ©rer cas oÃ¹ heic2any retourne Array de Blobs
    const blob = Array.isArray(convertedBlob) ? convertedBlob[0] : convertedBlob

    const convertedFile = new File(
      [blob],
      file.name.replace(/\.heic$/i, '.jpg'),
      {
        type: 'image/jpeg',
        lastModified: Date.now(),
      }
    )

    console.log(`âœ… HEIC converti : ${file.size} â†’ ${convertedFile.size} bytes`)
    return convertedFile
  } catch (error) {
    console.error('âŒ Erreur conversion HEIC:', error)
    throw new Error(
      "Impossible de convertir l'image HEIC. Essayez de la convertir en JPEG depuis votre tÃ©lÃ©phone."
    )
  }
}

/**
 * DÃ©tecte si fichier est HEIC
 * @param {File} file
 * @returns {boolean}
 */
export function isHEIC(file) {
  const type = file.type?.toLowerCase()
  const name = file.name?.toLowerCase()

  return (
    type === 'image/heic' ||
    type === 'image/heif' ||
    name.endsWith('.heic') ||
    name.endsWith('.heif')
  )
}
```

**âœ… RÃ©sultat attendu :**

- Module de conversion HEIC opÃ©rationnel
- Gestion erreurs explicite

---

### A2.3 - Validation unifiÃ©e images

**ğŸ¯ Objectif :** 1 fonction unique pour validation MIME + magic bytes

**ğŸ“ Action :**

**CrÃ©er :** `src/utils/images/imageValidator.js`

```javascript
// src/utils/images/imageValidator.js
// Validation complÃ¨te et unifiÃ©e des images

import { ALLOWED_MIME_TYPES } from '@/utils/images/config'

/**
 * Validation complÃ¨te d'un fichier image (MIME type + magic bytes)
 * @param {File} file - Fichier Ã  valider
 * @returns {Promise<{valid: boolean, error: string|null, normalizedType: string|null}>}
 */
export async function validateImageFile(file) {
  if (!file) {
    return {
      valid: false,
      error: 'Aucun fichier fourni',
      normalizedType: null,
    }
  }

  // 1ï¸âƒ£ Validation type MIME
  const rawType = String(file.type || '').toLowerCase()
  const normalizedType = rawType === 'image/jpg' ? 'image/jpeg' : rawType

  if (!ALLOWED_MIME_TYPES.includes(normalizedType)) {
    return {
      valid: false,
      error: `Format non supportÃ©.\nFormats acceptÃ©s : PNG, JPEG, WebP, SVG, HEIC`,
      normalizedType,
    }
  }

  // 2ï¸âƒ£ Validation Magic Bytes (sÃ©curitÃ© anti-spoofing)
  try {
    const buf = await file.slice(0, 16).arrayBuffer()
    const bytes = new Uint8Array(buf)

    // PNG : 89 50 4E 47 0D 0A 1A 0A
    const isPNG =
      bytes[0] === 0x89 &&
      bytes[1] === 0x50 &&
      bytes[2] === 0x4e &&
      bytes[3] === 0x47 &&
      bytes[4] === 0x0d &&
      bytes[5] === 0x0a &&
      bytes[6] === 0x1a &&
      bytes[7] === 0x0a

    // JPEG : FF D8
    const isJPEG = bytes[0] === 0xff && bytes[1] === 0xd8

    // WebP : "RIFF" .... "WEBP"
    const isWebP =
      bytes[0] === 0x52 && // R
      bytes[1] === 0x49 && // I
      bytes[2] === 0x46 && // F
      bytes[3] === 0x46 && // F
      bytes[8] === 0x57 && // W
      bytes[9] === 0x45 && // E
      bytes[10] === 0x42 && // B
      bytes[11] === 0x50 // P

    // SVG : Type textuel (pas de magic bytes fiables)
    const isSVG = normalizedType === 'image/svg+xml'

    // HEIC : Type-based uniquement (magic bytes complexes)
    const isHEIC =
      normalizedType === 'image/heic' || normalizedType === 'image/heif'

    if (isPNG || isJPEG || isWebP || isSVG || isHEIC) {
      return {
        valid: true,
        error: null,
        normalizedType,
      }
    }

    return {
      valid: false,
      error: 'Fichier corrompu ou type usurpÃ© (magic bytes invalides)',
      normalizedType,
    }
  } catch (error) {
    return {
      valid: false,
      error: 'Erreur lors de la lecture du fichier',
      normalizedType,
    }
  }
}
```

**âœ… RÃ©sultat attendu :**

- Validation unifiÃ©e (remplace 3 fonctions disparates)
- Support HEIC inclus
- Messages d'erreur clairs

---

### A2.4 - Conversion WebP moderne

**ğŸ¯ Objectif :** Conversion PNG/JPEG â†’ WebP â‰¤ 20 KB avec stratÃ©gies progressives

**ğŸ“ Action :**

**CrÃ©er :** `src/utils/images/webpConverter.js`

```javascript
// src/utils/images/webpConverter.js
// Conversion WebP moderne avec compression progressive â‰¤ 20 KB

import {
  TARGET_MAX_UI_SIZE_KB,
  FALLBACK_MAX_UI_SIZE_KB,
  TARGET_DIMENSION,
} from '@/utils/images/config'

/**
 * Convertit une image en WebP avec compression progressive
 * Objectif : â‰¤ 20 KB, dimensions 192Ã—192px (mobile-first TSA)
 *
 * @param {File} file - Fichier image original
 * @param {Object} options - Options compression
 * @returns {Promise<File|null>} - Fichier WebP compressÃ© ou null si Ã©chec
 */
export async function convertToWebP(file, options = {}) {
  const {
    targetSizeKB = TARGET_MAX_UI_SIZE_KB,
    fallbackSizeKB = FALLBACK_MAX_UI_SIZE_KB,
    maxDimension = TARGET_DIMENSION,
  } = options

  // SVG : pas de conversion (vecteur)
  if (file.type === 'image/svg+xml') {
    console.log('â„¹ï¸ SVG dÃ©tectÃ© â†’ aucune conversion')
    return file
  }

  // DÃ©jÃ  â‰¤ 20 KB ? â†’ retour tel quel
  if (file.size <= targetSizeKB * 1024) {
    console.log(`â„¹ï¸ Fichier dÃ©jÃ  â‰¤ ${targetSizeKB} KB â†’ aucune compression`)
    return file
  }

  return new Promise(resolve => {
    const img = new Image()
    const reader = new FileReader()

    reader.onload = e => {
      img.src = e.target.result
    }

    img.onload = () => {
      console.log(
        `ğŸ”„ Compression WebP : ${file.size} bytes (cible : ${targetSizeKB} KB)`
      )

      // StratÃ©gies de compression progressives
      const strategies = [
        // Tentative 192px @ qualitÃ©s dÃ©croissantes
        { dimension: 192, quality: 0.85 },
        { dimension: 192, quality: 0.75 },
        { dimension: 192, quality: 0.65 },
        { dimension: 192, quality: 0.55 },

        // RÃ©duction dimensions si nÃ©cessaire
        { dimension: 160, quality: 0.75 },
        { dimension: 160, quality: 0.6 },
        { dimension: 128, quality: 0.7 },
        { dimension: 128, quality: 0.5 },

        // Dernier recours (ultra-compressÃ©)
        { dimension: 96, quality: 0.6 },
      ]

      let currentTargetKB = targetSizeKB

      const tryCompression = async (strategyIndex = 0) => {
        if (strategyIndex >= strategies.length) {
          // Ã‰chec total â†’ essayer avec fallback 30 KB
          if (
            currentTargetKB === targetSizeKB &&
            fallbackSizeKB > targetSizeKB
          ) {
            console.warn(
              `âš ï¸ Impossible â‰¤ ${targetSizeKB} KB â†’ fallback ${fallbackSizeKB} KB`
            )
            currentTargetKB = fallbackSizeKB
            tryCompression(0) // Restart avec nouvelle cible
            return
          }

          console.error('âŒ Compression Ã©chouÃ©e (toutes stratÃ©gies Ã©puisÃ©es)')
          resolve(null)
          return
        }

        const strategy = strategies[strategyIndex]
        const canvas = document.createElement('canvas')

        // Calcul dimensions (respecter ratio)
        let { width, height } = img
        if (width > strategy.dimension || height > strategy.dimension) {
          const ratio = Math.min(
            strategy.dimension / width,
            strategy.dimension / height
          )
          width = Math.round(width * ratio)
          height = Math.round(height * ratio)
        }

        canvas.width = width
        canvas.height = height
        const ctx = canvas.getContext('2d')

        // AmÃ©liorer qualitÃ© rendu
        ctx.imageSmoothingEnabled = true
        ctx.imageSmoothingQuality = 'high'

        ctx.clearRect(0, 0, width, height)
        ctx.drawImage(img, 0, 0, width, height)

        canvas.toBlob(
          blob => {
            if (!blob) {
              tryCompression(strategyIndex + 1)
              return
            }

            const compressedFile = new File(
              [blob],
              file.name.replace(/\.\w+$/, '.webp'),
              {
                type: 'image/webp',
                lastModified: Date.now(),
              }
            )

            if (compressedFile.size <= currentTargetKB * 1024) {
              const compressionRatio = (
                ((file.size - compressedFile.size) / file.size) *
                100
              ).toFixed(1)

              console.log(
                `âœ… WebP compressÃ© : ${compressedFile.size} bytes (${width}Ã—${height}, qualitÃ© ${strategy.quality}, -${compressionRatio}%)`
              )

              resolve(compressedFile)
            } else {
              // Taille encore trop grande â†’ stratÃ©gie suivante
              tryCompression(strategyIndex + 1)
            }
          },
          'image/webp',
          strategy.quality
        )
      }

      tryCompression(0)
    }

    img.onerror = () => {
      console.error('âŒ Erreur chargement image pour conversion')
      resolve(null)
    }

    reader.onerror = () => {
      console.error('âŒ Erreur lecture fichier')
      resolve(null)
    }

    reader.readAsDataURL(file)
  })
}

/**
 * Calcule le hash SHA-256 d'un fichier (dÃ©duplication)
 * @param {File} file - Fichier Ã  hasher
 * @returns {Promise<string>} - Hash SHA-256 en hexadÃ©cimal (64 caractÃ¨res)
 */
export async function calculateFileHash(file) {
  const arrayBuffer = await file.arrayBuffer()
  const hashBuffer = await crypto.subtle.digest('SHA-256', arrayBuffer)
  const hashArray = Array.from(new Uint8Array(hashBuffer))
  const hash = hashArray.map(b => b.toString(16).padStart(2, '0')).join('')

  console.log(`ğŸ”‘ Hash SHA-256 calculÃ© : ${hash.slice(0, 16)}...`)
  return hash
}

/**
 * Extrait dimensions d'une image
 * @param {File} file - Fichier image
 * @returns {Promise<{width: number, height: number}>}
 */
export async function getImageDimensions(file) {
  return new Promise((resolve, reject) => {
    const img = new Image()
    const reader = new FileReader()

    reader.onload = e => {
      img.src = e.target.result
    }

    img.onload = () => {
      resolve({ width: img.width, height: img.height })
    }

    img.onerror = () => {
      reject(new Error('Impossible de lire les dimensions'))
    }

    reader.onerror = () => {
      reject(new Error('Erreur lecture fichier'))
    }

    reader.readAsDataURL(file)
  })
}
```

**âœ… RÃ©sultat attendu :**

- Conversion WebP avec fallback 30 KB
- Hash SHA-256 pour dÃ©duplication
- Extraction dimensions
- Logs dÃ©taillÃ©s pour debug

---

## Ã‰TAPE A3 : SERVICE UPLOAD MODERNE (4-5h)

### A3.1 - Retry logic avec backoff

**ğŸ¯ Objectif :** RÃ©essais automatiques sur rÃ©seau instable (3G/4G)

**ğŸ“ Action :**

**CrÃ©er :** `src/utils/upload/uploadWithRetry.js`

```javascript
// src/utils/upload/uploadWithRetry.js
// Retry automatique avec backoff exponentiel (rÃ©seau instable mobile)

/**
 * ExÃ©cute une fonction upload avec retry automatique
 * @param {Function} uploadFn - Fonction async Ã  exÃ©cuter
 * @param {Object} options - Options retry
 * @returns {Promise} - RÃ©sultat de uploadFn ou erreur finale
 */
export async function uploadWithRetry(uploadFn, options = {}) {
  const {
    maxRetries = 2,
    baseDelay = 1000, // 1s
    maxDelay = 5000, // 5s max
    onRetry = null, // Callback pour UI (toast, progress)
  } = options

  let lastError

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const result = await uploadFn()
      return result // SuccÃ¨s
    } catch (error) {
      lastError = error

      if (attempt < maxRetries) {
        // Backoff exponentiel : 1s â†’ 2s â†’ 5s
        const delay = Math.min(baseDelay * Math.pow(2, attempt), maxDelay)

        console.warn(
          `âš ï¸ Upload Ã©chouÃ© (tentative ${attempt + 1}/${maxRetries + 1}), retry dans ${delay}ms...`,
          error.message
        )

        // Callback UX (afficher toast "Connexion lente, rÃ©essai...")
        if (onRetry) {
          onRetry({
            attempt: attempt + 1,
            maxRetries,
            delay,
            error,
          })
        }

        // Attendre avant retry
        await new Promise(resolve => setTimeout(resolve, delay))
      }
    }
  }

  // Tous les retries Ã©puisÃ©s â†’ erreur finale
  console.error('âŒ Upload Ã©chouÃ© aprÃ¨s', maxRetries + 1, 'tentatives')
  throw lastError
}
```

**âœ… RÃ©sultat attendu :**

- Fonction rÃ©utilisable pour toute opÃ©ration async
- Backoff intelligent (1s â†’ 2s â†’ 5s)
- Callback UI pour feedback utilisateur

---

### A3.2 - Service upload moderne principal

**ğŸ¯ Objectif :** Upload complet avec HEIC, WebP, dÃ©duplication, retry, monitoring

**ğŸ“ Action :**

**CrÃ©er :** `src/utils/storage/modernUploadImage.js`

```javascript
// src/utils/storage/modernUploadImage.js
// Upload moderne images privÃ©es Supabase Storage
// Pipeline : HEIC â†’ WebP â†’ Hash â†’ DÃ©dup â†’ Quota â†’ Upload â†’ Metrics

import { supabase } from '@/utils/supabaseClient'
import { validateImageFile } from '@/utils/images/imageValidator'
import { convertHEICtoJPEG, isHEIC } from '@/utils/images/heicConverter'
import {
  convertToWebP,
  calculateFileHash,
  getImageDimensions,
} from '@/utils/images/webpConverter'
import { uploadWithRetry } from '@/utils/upload/uploadWithRetry'
import {
  TARGET_MAX_UI_SIZE_KB,
  PRIVATE_BUCKET,
  SIGNED_URL_TTL_SECONDS,
} from '@/utils/images/config'
import { buildScopedPath, sanitizeFileName } from '@/utils/storage/uploadImage'

/**
 * Upload moderne d'une image privÃ©e (Supabase Storage)
 *
 * Pipeline complet :
 * 1. Validation MIME + magic bytes
 * 2. Conversion HEIC â†’ JPEG (si iPhone)
 * 3. Conversion â†’ WebP â‰¤ 20 KB (sauf SVG)
 * 4. Calcul hash SHA-256 (dÃ©duplication)
 * 5. VÃ©rification quota utilisateur
 * 6. Upload avec retry (rÃ©seau instable)
 * 7. Enregistrement user_assets + metrics
 * 8. GÃ©nÃ©ration signed URL (TTL 24h)
 *
 * @param {File} file - Fichier image original
 * @param {Object} options - Options upload
 * @returns {Promise<{path, url, assetId, width, height, isDuplicate, error}>}
 */
export async function modernUploadImage(file, options = {}) {
  const {
    userId,
    assetType = 'task_image', // 'task_image' | 'reward_image'
    prefix = 'misc', // PrÃ©fixe chemin : 'taches', 'recompenses', 'misc'
    onProgress = null, // Callback progression (pour UI)
  } = options

  // MÃ©triques (monitoring)
  const metrics = {
    originalSize: file.size,
    compressedSize: file.size,
    conversionMs: null,
    uploadMs: null,
    result: 'success',
    errorMessage: null,
    mimeTypeOriginal: file.type,
    mimeTypeFinal: file.type,
    conversionMethod: 'none',
  }

  const startTime = Date.now()

  try {
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 1ï¸âƒ£ VALIDATION ENTRÃ‰E
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (!file) {
      throw new Error('Aucun fichier fourni')
    }

    if (!userId) {
      throw new Error('userId requis')
    }

    if (onProgress) {
      onProgress({ step: 'validation', progress: 5 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 2ï¸âƒ£ VALIDATION FICHIER (MIME + MAGIC BYTES)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const validation = await validateImageFile(file)

    if (!validation.valid) {
      throw new Error(validation.error)
    }

    if (onProgress) {
      onProgress({ step: 'validation', progress: 10 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 3ï¸âƒ£ CONVERSION HEIC â†’ JPEG (si iPhone)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    let processedFile = file
    const conversionStart = Date.now()

    if (isHEIC(file)) {
      console.log('ğŸ“± iPhone HEIC dÃ©tectÃ© â†’ conversion JPEG...')

      processedFile = await convertHEICtoJPEG(file)
      metrics.conversionMethod = 'heic_to_jpeg_then_webp'

      if (onProgress) {
        onProgress({ step: 'heic_conversion', progress: 20 })
      }
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 4ï¸âƒ£ CONVERSION â†’ WEBP â‰¤ 20 KB (sauf SVG)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (processedFile.type !== 'image/svg+xml') {
      const webpFile = await convertToWebP(processedFile, {
        targetSizeKB: TARGET_MAX_UI_SIZE_KB,
      })

      if (!webpFile) {
        // Fallback : accepter original si < 100 KB
        if (processedFile.size <= 100 * 1024) {
          console.warn('âš ï¸ Compression WebP Ã©chouÃ©e â†’ upload original')
          metrics.conversionMethod =
            metrics.conversionMethod === 'heic_to_jpeg_then_webp'
              ? 'heic_to_jpeg_only'
              : 'fallback_original'
          metrics.result = 'fallback_original'
        } else {
          throw new Error(
            'Image trop lourde et compression impossible.\nEssayez une image plus simple ou de meilleure qualitÃ©.'
          )
        }
      } else {
        processedFile = webpFile
        metrics.mimeTypeFinal = 'image/webp'

        if (metrics.conversionMethod === 'none') {
          metrics.conversionMethod = 'client_webp'
        }
      }
    } else {
      metrics.conversionMethod = 'svg_unchanged'
    }

    metrics.compressedSize = processedFile.size
    metrics.conversionMs = Date.now() - conversionStart

    if (onProgress) {
      onProgress({ step: 'compression', progress: 40 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 5ï¸âƒ£ CALCUL HASH SHA-256 (dÃ©duplication)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const fileHash = await calculateFileHash(processedFile)

    if (onProgress) {
      onProgress({ step: 'hash', progress: 50 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 6ï¸âƒ£ VÃ‰RIFICATION DUPLICATION
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const { data: duplicateCheck, error: dupError } = await supabase.rpc(
      'check_duplicate_image',
      {
        p_user_id: userId,
        p_sha256_hash: fileHash,
      }
    )

    if (dupError) {
      console.error('Erreur vÃ©rification duplication:', dupError)
      // Continue malgrÃ© erreur (non bloquant)
    }

    if (duplicateCheck?.exists) {
      console.log('â™»ï¸ Image identique trouvÃ©e â†’ rÃ©utilisation asset existant')

      // Log metric duplication
      await logMetrics(userId, assetType, metrics)

      return {
        path: duplicateCheck.file_path,
        url: null, // GÃ©nÃ©rÃ© plus tard si besoin
        assetId: duplicateCheck.asset_id,
        width: duplicateCheck.width,
        height: duplicateCheck.height,
        isDuplicate: true,
        error: null,
      }
    }

    if (onProgress) {
      onProgress({ step: 'deduplication', progress: 60 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 7ï¸âƒ£ VÃ‰RIFICATION QUOTA UTILISATEUR
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const { data: quotaCheck, error: quotaError } = await supabase.rpc(
      'check_image_quota',
      {
        p_user_id: userId,
        p_asset_type: assetType,
        p_file_size: processedFile.size,
      }
    )

    if (quotaError) {
      console.error('Erreur vÃ©rification quota:', quotaError)
      throw new Error('Impossible de vÃ©rifier les quotas')
    }

    if (!quotaCheck?.can_upload) {
      const reason = quotaCheck?.reason || 'limite atteinte'

      const messages = {
        task_image_limit_reached: 'Quota de tÃ¢ches atteint',
        reward_image_limit_reached: 'Quota de rÃ©compenses atteint',
        total_image_limit_reached: "Quota total d'images atteint",
        image_too_large: 'Image trop volumineuse',
      }

      throw new Error(messages[reason] || `Quota dÃ©passÃ© : ${reason}`)
    }

    if (onProgress) {
      onProgress({ step: 'quota', progress: 70 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 8ï¸âƒ£ EXTRAIRE DIMENSIONS
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const { width, height } = await getImageDimensions(processedFile)

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 9ï¸âƒ£ UPLOAD SUPABASE STORAGE (avec retry)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const fileName = sanitizeFileName(processedFile.name)
    const storagePath = buildScopedPath(userId, fileName, prefix)

    const uploadStart = Date.now()

    const { data: storageData, error: storageError } = await uploadWithRetry(
      () =>
        supabase.storage
          .from(PRIVATE_BUCKET)
          .upload(storagePath, processedFile, {
            cacheControl: `${SIGNED_URL_TTL_SECONDS}`, // 24h
            upsert: false,
            contentType: processedFile.type,
          }),
      {
        maxRetries: 2,
        onRetry: ({ attempt, maxRetries }) => {
          console.log(`ğŸ”„ RÃ©essai upload ${attempt}/${maxRetries}...`)

          if (onProgress) {
            onProgress({
              step: 'upload_retry',
              progress: 70 + attempt * 5,
              message: `Connexion lente, rÃ©essai ${attempt}...`,
            })
          }
        },
      }
    )

    if (storageError) {
      console.error('âŒ Erreur upload Supabase Storage:', storageError)
      throw storageError
    }

    metrics.uploadMs = Date.now() - uploadStart

    if (onProgress) {
      onProgress({ step: 'upload', progress: 85 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // ğŸ”Ÿ ENREGISTREMENT USER_ASSETS
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const { data: asset, error: dbError } = await supabase
      .from('user_assets')
      .insert({
        user_id: userId,
        asset_type: assetType,
        file_path: storageData.path,
        file_size: processedFile.size,
        mime_type: processedFile.type,
        width,
        height,
        sha256_hash: fileHash,
        version: 1,
      })
      .select('id')
      .single()

    if (dbError) {
      console.error('âŒ Erreur enregistrement BDD:', dbError)

      // GÃ©rer erreur unicitÃ© (23505 - race condition dÃ©duplication)
      if (dbError.code === '23505') {
        console.warn('âš ï¸ Hash en conflit â†’ rÃ©cupÃ©ration asset existant')

        const { data: existing } = await supabase
          .from('user_assets')
          .select('id, file_path, width, height')
          .eq('user_id', userId)
          .eq('sha256_hash', fileHash)
          .single()

        if (existing) {
          // Cleanup fichier uploadÃ© (duplication dÃ©tectÃ©e aprÃ¨s coup)
          await supabase.storage.from(PRIVATE_BUCKET).remove([storageData.path])

          // Log metric
          await logMetrics(userId, assetType, metrics)

          return {
            path: existing.file_path,
            url: null,
            assetId: existing.id,
            width: existing.width,
            height: existing.height,
            isDuplicate: true,
            error: null,
          }
        }
      }

      // Cleanup storage si BDD fail (orphelin)
      await supabase.storage.from(PRIVATE_BUCKET).remove([storageData.path])

      throw dbError
    }

    if (onProgress) {
      onProgress({ step: 'database', progress: 95 })
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 1ï¸âƒ£1ï¸âƒ£ GÃ‰NÃ‰RATION SIGNED URL (TTL 24h)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const { data: signedData, error: signError } = await supabase.storage
      .from(PRIVATE_BUCKET)
      .createSignedUrl(storageData.path, SIGNED_URL_TTL_SECONDS)

    if (signError) {
      console.error('âš ï¸ Erreur gÃ©nÃ©ration signed URL:', signError)
      // Non bloquant â†’ URL gÃ©nÃ©rÃ©e plus tard si besoin
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 1ï¸âƒ£2ï¸âƒ£ LOG METRICS (analytics)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    await logMetrics(userId, assetType, metrics)

    if (onProgress) {
      onProgress({ step: 'complete', progress: 100 })
    }

    console.log('âœ… Upload rÃ©ussi:', storageData.path)

    return {
      path: storageData.path,
      url: signedData?.signedUrl || null,
      assetId: asset.id,
      width,
      height,
      isDuplicate: false,
      error: null,
    }
  } catch (error) {
    console.error('âŒ Upload Ã©chouÃ©:', error)

    metrics.result = 'failed'
    metrics.errorMessage = error.message

    // Log metric Ã©chec
    await logMetrics(userId, assetType, metrics)

    return {
      path: null,
      url: null,
      assetId: null,
      width: null,
      height: null,
      isDuplicate: false,
      error,
    }
  }
}

/**
 * Log metrics upload (analytics)
 * @param {string} userId
 * @param {string} assetType
 * @param {Object} metrics
 */
async function logMetrics(userId, assetType, metrics) {
  try {
    await supabase.from('image_metrics').insert({
      user_id: userId,
      asset_type: assetType,
      original_size: metrics.originalSize,
      compressed_size: metrics.compressedSize,
      conversion_ms: metrics.conversionMs,
      upload_ms: metrics.uploadMs,
      result: metrics.result,
      error_message: metrics.errorMessage,
      mime_type_original: metrics.mimeTypeOriginal,
      mime_type_final: metrics.mimeTypeFinal,
      conversion_method: metrics.conversionMethod,
    })
  } catch (error) {
    console.error('âš ï¸ Erreur log metrics:', error)
    // Non bloquant
  }
}

/**
 * Remplace une image existante (incrÃ©mente version)
 * @param {string} assetId - ID asset Ã  remplacer
 * @param {File} newFile - Nouveau fichier
 * @param {Object} options - Options (userId, onProgress)
 * @returns {Promise<{path, url, version, error}>}
 */
export async function replaceImage(assetId, newFile, options = {}) {
  const { userId, onProgress } = options

  if (!userId) {
    return { path: null, url: null, error: new Error('userId requis') }
  }

  try {
    // RÃ©cupÃ©rer asset existant
    const { data: existingAsset, error: fetchError } = await supabase
      .from('user_assets')
      .select('*')
      .eq('id', assetId)
      .eq('user_id', userId)
      .single()

    if (fetchError || !existingAsset) {
      throw new Error('Asset introuvable')
    }

    // Upload nouvelle version
    const uploadResult = await modernUploadImage(newFile, {
      userId,
      assetType: existingAsset.asset_type,
      prefix:
        existingAsset.asset_type === 'task_image' ? 'taches' : 'recompenses',
      onProgress,
    })

    if (uploadResult.error) {
      return uploadResult
    }

    // Soft delete ancienne version
    await supabase
      .from('user_assets')
      .update({ deleted_at: new Date().toISOString() })
      .eq('id', assetId)

    // IncrÃ©menter version nouvel asset
    const newVersion = (existingAsset.version || 1) + 1

    await supabase
      .from('user_assets')
      .update({ version: newVersion })
      .eq('id', uploadResult.assetId)

    console.log(
      `â™»ï¸ Image remplacÃ©e : v${existingAsset.version} â†’ v${newVersion}`
    )

    // TODO : Invalider cache Service Worker (Phase A4)

    return {
      ...uploadResult,
      version: newVersion,
    }
  } catch (error) {
    console.error('âŒ Erreur remplacement image:', error)
    return { path: null, url: null, error }
  }
}
```

**âœ… RÃ©sultat attendu :**

- Pipeline complet upload images privÃ©es
- Support HEIC + WebP + dÃ©duplication
- Retry automatique
- Monitoring complet
- Gestion erreurs robuste

---

### A3.3 - Tests unitaires WebP converter

**ğŸ¯ Objectif :** Valider logique conversion + hash

**ğŸ“ Action :**

**CrÃ©er :** `src/utils/images/webpConverter.test.js`

```javascript
// src/utils/images/webpConverter.test.js
import { describe, it, expect } from 'vitest'
import { convertToWebP, calculateFileHash } from './webpConverter'

describe('webpConverter', () => {
  it('ne convertit pas SVG', async () => {
    const mockSvg = new File(['<svg></svg>'], 'test.svg', {
      type: 'image/svg+xml',
    })

    const result = await convertToWebP(mockSvg)

    expect(result).toBe(mockSvg) // Retour tel quel
  })

  it('retourne fichier si dÃ©jÃ  â‰¤ 20 KB', async () => {
    const smallFile = new File([new ArrayBuffer(10 * 1024)], 'small.png', {
      type: 'image/png',
    })

    const result = await convertToWebP(smallFile)

    expect(result).toBe(smallFile) // Aucune conversion
  })

  it('calcule hash SHA-256 (64 hex chars)', async () => {
    const mockFile = new File(['test content'], 'test.txt', {
      type: 'text/plain',
    })

    const hash = await calculateFileHash(mockFile)

    expect(hash).toHaveLength(64) // SHA-256 = 64 caractÃ¨res hex
    expect(hash).toMatch(/^[0-9a-f]{64}$/) // Hex uniquement
  })

  it('calcule hash identique pour contenu identique', async () => {
    const file1 = new File(['same content'], 'file1.txt')
    const file2 = new File(['same content'], 'file2.txt')

    const hash1 = await calculateFileHash(file1)
    const hash2 = await calculateFileHash(file2)

    expect(hash1).toBe(hash2) // DÃ©duplication fonctionnelle
  })
})
```

**Commandes :**

```bash
yarn test src/utils/images/webpConverter.test.js
```

**âœ… RÃ©sultat attendu :**

- Tests de base passent
- Validation dÃ©duplication hash

---

## Ã‰TAPE A4 : SERVICE WORKER - CACHE OFFLINE (3-4h)

### A4.1 - Service Worker avec placeholder TSA-friendly

**ğŸ¯ Objectif :** Cache intelligent 1h + placeholder SVG apaisant (pas d'image cassÃ©e)

**ğŸ“ Action :**

**CrÃ©er :** `public/sw.js`

```javascript
// public/sw.js
// Service Worker : Cache offline images avec stratÃ©gie TSA-friendly

const CACHE_VERSION = 'appli-picto-v1'
const IMAGE_CACHE = 'appli-picto-images-v1'
const STATIC_CACHE = 'appli-picto-static-v1'

// Assets statiques Ã  prÃ©-cacher
const STATIC_ASSETS = ['/', '/index.html', '/manifest.json']

// Placeholder SVG apaisant (TSA-friendly : pas d'image cassÃ©e)
const PLACEHOLDER_SVG = `<svg xmlns="http://www.w3.org/2000/svg" width="192" height="192" viewBox="0 0 192 192">
  <rect fill="#E8F4F8" width="192" height="192"/>
  <circle cx="96" cy="96" r="40" fill="#B8E0F0" opacity="0.5"/>
  <text x="96" y="105" font-family="Arial" font-size="12" fill="#5A9FB8" text-anchor="middle">Chargement...</text>
</svg>`

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// INSTALL : PrÃ©-cache assets statiques
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
self.addEventListener('install', event => {
  console.log('ğŸ“¦ Service Worker : Installation...')

  event.waitUntil(
    caches.open(STATIC_CACHE).then(cache => {
      return cache.addAll(STATIC_ASSETS)
    })
  )

  self.skipWaiting()
})

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ACTIVATE : Nettoyer vieux caches
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
self.addEventListener('activate', event => {
  console.log('ğŸ”„ Service Worker : Activation...')

  event.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames
          .filter(name => {
            return (
              name !== IMAGE_CACHE &&
              name !== STATIC_CACHE &&
              name !== CACHE_VERSION
            )
          })
          .map(name => {
            console.log('ğŸ—‘ï¸ Suppression vieux cache:', name)
            return caches.delete(name)
          })
      )
    })
  )

  self.clients.claim()
})

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// FETCH : StratÃ©gie cache pour images
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
self.addEventListener('fetch', event => {
  const { request } = event
  const url = new URL(request.url)

  // StratÃ©gie cache modÃ©rÃ© pour images (Supabase Storage)
  if (
    request.destination === 'image' ||
    url.hostname.includes('supabase.co') ||
    url.pathname.includes('/storage/v1/object/')
  ) {
    event.respondWith(
      caches.open(IMAGE_CACHE).then(cache => {
        return cache.match(request).then(cachedResponse => {
          // VÃ©rifier fraÃ®cheur cache (max 1 heure)
          if (cachedResponse) {
            const cacheDate = new Date(cachedResponse.headers.get('date'))
            const now = new Date()
            const ageMinutes = (now - cacheDate) / 1000 / 60

            // Cache rÃ©cent (< 1h) â†’ servir
            if (ageMinutes < 60) {
              console.log('âœ… Cache hit (frais) :', url.pathname.slice(-30))
              return cachedResponse
            } else {
              console.log('âš ï¸ Cache pÃ©rimÃ© (> 1h), fetch rÃ©seau...')
            }
          }

          // Cache miss ou pÃ©rimÃ© â†’ fetch rÃ©seau
          return fetch(request)
            .then(networkResponse => {
              // Cache si succÃ¨s
              if (networkResponse.ok) {
                cache.put(request, networkResponse.clone())
              }
              return networkResponse
            })
            .catch(error => {
              console.error('âŒ Fetch image Ã©chouÃ©:', error.message)

              // Offline â†’ servir cache pÃ©rimÃ© si existe
              if (cachedResponse) {
                console.log('ğŸ“´ Mode offline â†’ cache pÃ©rimÃ© utilisÃ© (fallback)')
                return cachedResponse
              }

              // Pas de cache â†’ placeholder SVG apaisant
              console.log('ğŸ–¼ï¸ Affichage placeholder (aucun cache)')
              return new Response(PLACEHOLDER_SVG, {
                status: 200,
                headers: {
                  'Content-Type': 'image/svg+xml',
                  'Cache-Control': 'no-cache',
                },
              })
            })
        })
      })
    )
    return
  }

  // StratÃ©gie network-first pour le reste
  event.respondWith(
    fetch(request).catch(() => {
      return caches.match(request)
    })
  )
})

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// MESSAGE : Invalider cache spÃ©cifique
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
self.addEventListener('message', event => {
  if (event.data && event.data.type === 'INVALIDATE_IMAGE') {
    const { url } = event.data
    console.log('ğŸ—‘ï¸ Invalidation cache image:', url)

    caches.open(IMAGE_CACHE).then(cache => {
      cache.delete(url)
    })
  }

  if (event.data && event.data.type === 'CLEAR_ALL_CACHE') {
    console.log('ğŸ—‘ï¸ Vidage total cache')

    caches.keys().then(cacheNames => {
      return Promise.all(cacheNames.map(name => caches.delete(name)))
    })
  }
})
```

**âœ… RÃ©sultat attendu :**

- Cache intelligent 1h (pas 1 an = trop agressif)
- Placeholder SVG apaisant (TSA-friendly)
- Invalidation cache possible

---

### A4.2 - Utilitaires enregistrement Service Worker

**ğŸ¯ Objectif :** Enregistrer SW + helper invalidation cache

**ğŸ“ Action :**

**CrÃ©er :** `src/utils/serviceWorker/register.js`

```javascript
// src/utils/serviceWorker/register.js
// Enregistrement et gestion Service Worker

/**
 * Enregistre le Service Worker (production uniquement)
 * @returns {Promise<ServiceWorkerRegistration|null>}
 */
export async function registerServiceWorker() {
  if (!('serviceWorker' in navigator)) {
    console.warn('âš ï¸ Service Worker non supportÃ© par ce navigateur')
    return null
  }

  if (import.meta.env.DEV) {
    console.log('ğŸ› ï¸ Mode dev â†’ Service Worker dÃ©sactivÃ©')
    return null
  }

  try {
    const registration = await navigator.serviceWorker.register('/sw.js', {
      scope: '/',
    })

    console.log('âœ… Service Worker enregistrÃ©:', registration.scope)

    // VÃ©rifier updates pÃ©riodiquement (1h)
    setInterval(
      () => {
        registration.update()
      },
      60 * 60 * 1000
    )

    return registration
  } catch (error) {
    console.error('âŒ Erreur enregistrement Service Worker:', error)
    return null
  }
}

/**
 * Invalide le cache d'une image spÃ©cifique
 * Usage : AprÃ¨s remplacement image
 * @param {string} url - URL image Ã  invalider
 */
export async function invalidateImageCache(url) {
  if (!navigator.serviceWorker.controller) {
    console.warn('âš ï¸ Pas de Service Worker actif')
    return
  }

  navigator.serviceWorker.controller.postMessage({
    type: 'INVALIDATE_IMAGE',
    url,
  })

  console.log('ğŸ—‘ï¸ Invalidation cache demandÃ©e:', url)
}

/**
 * Vide tout le cache (debug/admin)
 */
export async function clearAllCache() {
  if (!navigator.serviceWorker.controller) {
    console.warn('âš ï¸ Pas de Service Worker actif')
    return
  }

  navigator.serviceWorker.controller.postMessage({
    type: 'CLEAR_ALL_CACHE',
  })

  console.log('ğŸ—‘ï¸ Vidage total cache demandÃ©')
}
```

**âœ… RÃ©sultat attendu :**

- Enregistrement SW sÃ©curisÃ©
- Helpers invalidation cache

---

### A4.3 - Activer Service Worker dans main.jsx

**ğŸ¯ Objectif :** Charger SW au dÃ©marrage app (production uniquement)

**ğŸ“ Action :**

**Modifier :** `src/main.jsx`

```javascript
// src/main.jsx
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App'
import { registerServiceWorker } from '@/utils/serviceWorker/register'
import './styles/main.scss'

// ğŸ†• Enregistrer Service Worker (production uniquement)
if (import.meta.env.PROD) {
  registerServiceWorker().then(registration => {
    if (registration) {
      console.log('âœ… Service Worker prÃªt')
    }
  })
}

ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
)
```

**âœ… RÃ©sultat attendu :**

- Service Worker actif en production
- DÃ©sactivÃ© en dev (Ã©vite confusion)

---

## Ã‰TAPE A5 : INTÃ‰GRATION HOOKS & COMPOSANTS (2-3h)

### A5.1 - Adapter hook `useTachesEdition`

**ğŸ¯ Objectif :** Utiliser `modernUploadImage()` au lieu de `uploadImage()`

**ğŸ“ Action :**

**Modifier :** `src/hooks/useTachesEdition.js`

```javascript
// src/hooks/useTachesEdition.js
import { useState } from 'react'
import { supabase } from '@/utils/supabaseClient'
import { useAuth } from '@/hooks/useAuth'
import { modernUploadImage } from '@/utils/storage/modernUploadImage' // ğŸ†•
// ... autres imports

export function useTachesEdition() {
  const { user } = useAuth()
  const [loading, setLoading] = useState(false)
  const [error, setError] = useState(null)

  /**
   * CrÃ©er tÃ¢che avec upload image moderne
   * @param {File} file - Fichier image
   * @param {Object} fields - Champs tÃ¢che (label, etc.)
   */
  const addTacheFromFile = async (file, fields = {}) => {
    setLoading(true)
    setError(null)

    try {
      // ğŸ†• Upload moderne avec WebP + dÃ©duplication
      const uploadResult = await modernUploadImage(file, {
        userId: user.id,
        assetType: 'task_image',
        prefix: 'taches',
      })

      if (uploadResult.error) {
        throw uploadResult.error
      }

      // CrÃ©er tÃ¢che avec path uploadÃ©
      const newTache = {
        label: fields.label || 'Nouvelle tÃ¢che',
        imagepath: uploadResult.path,
        user_id: user.id,
        ...fields,
      }

      const { data, error: dbError } = await supabase
        .from('taches')
        .insert(newTache)
        .select()
        .single()

      if (dbError) throw dbError

      console.log('âœ… TÃ¢che crÃ©Ã©e:', data.id)

      return { data, error: null }
    } catch (err) {
      console.error('âŒ Erreur crÃ©ation tÃ¢che:', err)
      setError(err.message)
      return { data: null, error: err }
    } finally {
      setLoading(false)
    }
  }

  /**
   * Mettre Ã  jour image tÃ¢che existante
   * @param {string} tacheId - ID tÃ¢che
   * @param {File} newFile - Nouveau fichier
   */
  const updateTacheImage = async (tacheId, newFile) => {
    setLoading(true)
    setError(null)

    try {
      // RÃ©cupÃ©rer asset_id actuel
      const { data: tache } = await supabase
        .from('taches')
        .select('imagepath')
        .eq('id', tacheId)
        .single()

      if (!tache?.imagepath) {
        throw new Error('TÃ¢che sans image associÃ©e')
      }

      // Trouver asset correspondant
      const { data: asset } = await supabase
        .from('user_assets')
        .select('id')
        .eq('user_id', user.id)
        .eq('file_path', tache.imagepath)
        .single()

      if (!asset) {
        throw new Error('Asset introuvable')
      }

      // ğŸ†• Remplacer image (incrÃ©mente version)
      const { replaceImage } = await import('@/utils/storage/modernUploadImage')

      const replaceResult = await replaceImage(asset.id, newFile, {
        userId: user.id,
      })

      if (replaceResult.error) {
        throw replaceResult.error
      }

      // Mettre Ã  jour chemin dans tÃ¢che
      await supabase
        .from('taches')
        .update({ imagepath: replaceResult.path })
        .eq('id', tacheId)

      console.log(
        'âœ… Image tÃ¢che mise Ã  jour (version',
        replaceResult.version,
        ')'
      )

      return { data: replaceResult, error: null }
    } catch (err) {
      console.error('âŒ Erreur mise Ã  jour image:', err)
      setError(err.message)
      return { data: null, error: err }
    } finally {
      setLoading(false)
    }
  }

  return {
    addTacheFromFile,
    updateTacheImage,
    loading,
    error,
  }
}
```

**âœ… RÃ©sultat attendu :**

- Hook adaptÃ© au nouveau systÃ¨me
- Support WebP + dÃ©duplication
- Versioning images

---

### A5.2 - Composant Progress Indicator TSA-friendly

**ğŸ¯ Objectif :** Feedback visuel rassurant pendant upload (enfants TSA)

**ğŸ“ Action :**

**CrÃ©er :** `src/components/ui/upload-progress/UploadProgress.jsx`

```jsx
// src/components/ui/upload-progress/UploadProgress.jsx
import PropTypes from 'prop-types'
import './UploadProgress.scss'

/**
 * Indicateur progression upload TSA-friendly
 * @param {number} progress - Progression 0-100
 * @param {string} message - Message contextuel
 */
export default function UploadProgress({
  progress = 0,
  message = 'Envoi en cours...',
}) {
  return (
    <div
      className="upload-progress"
      role="status"
      aria-live="polite"
      aria-busy="true"
    >
      <div className="upload-progress__bar" aria-hidden="true">
        <div
          className="upload-progress__fill"
          style={{ width: `${Math.min(progress, 100)}%` }}
        />
      </div>
      <p className="upload-progress__message">{message}</p>
      <span className="upload-progress__percent">{Math.round(progress)}%</span>
    </div>
  )
}

UploadProgress.propTypes = {
  progress: PropTypes.number,
  message: PropTypes.string,
}
```

**CrÃ©er :** `src/components/ui/upload-progress/UploadProgress.scss`

```scss
// src/components/ui/upload-progress/UploadProgress.scss
.upload-progress {
  padding: 1rem;
  text-align: center;
  background: var(--pastel-blue-lightest);
  border-radius: 8px;

  &__bar {
    width: 100%;
    height: 8px;
    background-color: var(--pastel-blue-light);
    border-radius: 4px;
    overflow: hidden;
    margin-bottom: 0.75rem;
  }

  &__fill {
    height: 100%;
    background: linear-gradient(90deg, var(--pastel-blue), var(--pastel-green));
    transition: width 0.3s ease; // Animation douce (TSA-friendly)
    border-radius: 4px;
  }

  &__message {
    font-size: 0.875rem;
    color: var(--text-dark);
    margin: 0 0 0.25rem 0;
    font-weight: 500;
  }

  &__percent {
    font-size: 0.75rem;
    color: var(--text-muted);
    font-weight: 400;
  }
}
```

**Utiliser dans `ItemForm.jsx` :**

```jsx
// src/components/shared/forms/ItemForm.jsx
import { useState } from 'react'
import UploadProgress from '@/components/ui/upload-progress/UploadProgress'
import { modernUploadImage } from '@/utils/storage/modernUploadImage'

export default function ItemForm({ onSubmit, type = 'task' }) {
  const [uploadProgress, setUploadProgress] = useState(null)

  const handleFileSelect = async file => {
    // Afficher progress
    setUploadProgress({ progress: 0, message: "Validation de l'image..." })

    try {
      const result = await modernUploadImage(file, {
        userId: user.id,
        assetType: type === 'task' ? 'task_image' : 'reward_image',
        prefix: type === 'task' ? 'taches' : 'recompenses',
        onProgress: state => {
          const messages = {
            validation: 'VÃ©rification...',
            heic_conversion: 'Conversion iPhone...',
            compression: 'Optimisation...',
            hash: 'VÃ©rification doublons...',
            quota: 'VÃ©rification quota...',
            upload: 'Envoi...',
            upload_retry: state.message || 'Connexion lente, rÃ©essai...',
            database: 'Finalisation...',
            complete: 'TerminÃ© !',
          }

          setUploadProgress({
            progress: state.progress,
            message: messages[state.step] || 'Traitement...',
          })
        },
      })

      if (result.error) {
        throw result.error
      }

      // Success â†’ fermer progress
      setUploadProgress(null)
      onSubmit(result)
    } catch (error) {
      setUploadProgress(null)
      // Afficher erreur via toast
    }
  }

  return (
    <div className="item-form">
      {uploadProgress && (
        <UploadProgress
          progress={uploadProgress.progress}
          message={uploadProgress.message}
        />
      )}

      {/* ... reste du form */}
    </div>
  )
}
```

**âœ… RÃ©sultat attendu :**

- Progress bar TSA-friendly (couleurs pastel, animation douce)
- Messages contextuels clairs
- AccessibilitÃ© (role, aria-live)

---

## Ã‰TAPE A6 : MIGRATION & MONITORING (2-3h)

### A6.1 - Script migration images existantes

**ğŸ¯ Objectif :** Migrer anciennes images (ajouter hash, dimensions, migrated_at)

**ğŸ“ Action :**

**CrÃ©er :** `scripts/migrate-existing-images.js`

```javascript
// scripts/migrate-existing-images.js
// Migration images existantes vers nouveau systÃ¨me (hash SHA-256 + dimensions)

import { createClient } from '@supabase/supabase-js'
import dotenv from 'dotenv'
import fs from 'fs'

dotenv.config()

const supabase = createClient(
  process.env.VITE_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
)

const BATCH_SIZE = 10
const PAUSE_MS = 2000

// Rapport migration
const report = {
  total: 0,
  success: 0,
  failed: 0,
  errors: [],
}

async function migrateImages(dryRun = true, limit = null) {
  console.log(`\nğŸš€ Migration images vers nouveau systÃ¨me`)
  console.log(`Mode : ${dryRun ? 'ğŸ§ª DRY RUN (test)' : 'ğŸ”´ LIVE (production)'}`)

  // RÃ©cupÃ©rer assets sans hash (= anciennes images)
  let query = supabase.from('user_assets').select('*').is('sha256_hash', null)

  if (limit) {
    query = query.limit(limit)
    console.log(`Limite : ${limit} images`)
  }

  const { data: assets, error } = await query

  if (error) {
    console.error('âŒ Erreur rÃ©cupÃ©ration assets:', error)
    return
  }

  report.total = assets.length
  console.log(`ğŸ“¦ ${assets.length} images Ã  migrer\n`)

  // Migration par batch
  for (let i = 0; i < assets.length; i += BATCH_SIZE) {
    const batch = assets.slice(i, i + BATCH_SIZE)
    const batchNum = Math.floor(i / BATCH_SIZE) + 1
    const totalBatches = Math.ceil(assets.length / BATCH_SIZE)

    console.log(
      `\nğŸ“¦ Batch ${batchNum}/${totalBatches} (${batch.length} images)`
    )
    console.log('â”€'.repeat(60))

    for (const asset of batch) {
      try {
        // TÃ©lÃ©charger fichier
        const { data: fileData, error: downloadError } = await supabase.storage
          .from('images')
          .download(asset.file_path)

        if (downloadError || !fileData) {
          throw new Error(`TÃ©lÃ©chargement Ã©chouÃ©: ${downloadError?.message}`)
        }

        // Calculer hash SHA-256
        const arrayBuffer = await fileData.arrayBuffer()
        const hashBuffer = await crypto.subtle.digest('SHA-256', arrayBuffer)
        const hashArray = Array.from(new Uint8Array(hashBuffer))
        const hash = hashArray
          .map(b => b.toString(16).padStart(2, '0'))
          .join('')

        // Extraire dimensions (si image bitmap)
        let width = null
        let height = null

        if (
          asset.mime_type?.startsWith('image/') &&
          asset.mime_type !== 'image/svg+xml'
        ) {
          try {
            const bitmap = await createImageBitmap(fileData)
            width = bitmap.width
            height = bitmap.height
            bitmap.close()
          } catch (e) {
            console.warn(`  âš ï¸ Dimensions non extraites (${asset.mime_type})`)
          }
        }

        if (!dryRun) {
          // Mise Ã  jour BDD
          const { error: updateError } = await supabase
            .from('user_assets')
            .update({
              sha256_hash: hash,
              width,
              height,
              migrated_at: new Date().toISOString(),
            })
            .eq('id', asset.id)

          if (updateError) {
            throw new Error(`Update BDD Ã©chouÃ©: ${updateError.message}`)
          }
        }

        const dimensionsStr = width && height ? `${width}Ã—${height}` : 'N/A'

        console.log(
          `  âœ… ${asset.file_path.slice(-40)} (${dimensionsStr}, hash: ${hash.slice(0, 8)}...)`
        )

        report.success++
      } catch (error) {
        console.error(`  âŒ ${asset.file_path.slice(-40)} :`, error.message)

        report.failed++
        report.errors.push({
          assetId: asset.id,
          filePath: asset.file_path,
          error: error.message,
        })
      }
    }

    // Pause entre batches
    if (i + BATCH_SIZE < assets.length) {
      console.log(`\nâ¸ï¸  Pause ${PAUSE_MS}ms...`)
      await new Promise(resolve => setTimeout(resolve, PAUSE_MS))
    }
  }

  // Rapport final
  console.log('\n' + 'â•'.repeat(60))
  console.log('ğŸ“Š RAPPORT DE MIGRATION')
  console.log('â•'.repeat(60))
  console.log(`Total     : ${report.total}`)
  console.log(`âœ… SuccÃ¨s : ${report.success}`)
  console.log(`âŒ Ã‰checs : ${report.failed}`)

  if (report.errors.length > 0) {
    const errorLog = `migration-errors-${Date.now()}.json`
    fs.writeFileSync(errorLog, JSON.stringify(report.errors, null, 2))
    console.log(`\nâš ï¸  Erreurs dÃ©taillÃ©es â†’ ${errorLog}`)
  }

  if (dryRun) {
    console.log('\nğŸ§ª DRY RUN terminÃ© - AUCUNE modification appliquÃ©e')
    console.log('ğŸ’¡ ExÃ©cutez avec --live pour migration rÃ©elle')
  } else {
    console.log('\nğŸ‰ Migration terminÃ©e !')
  }
}

// CLI
const args = process.argv.slice(2)
const dryRun = !args.includes('--live')
const limitArg = args.find(arg => arg.startsWith('--limit='))
const limit = limitArg ? parseInt(limitArg.split('=')[1]) : null

migrateImages(dryRun, limit).catch(console.error)
```

**Usage :**

```bash
# 1. Test sur 10 images (DRY RUN)
node scripts/migrate-existing-images.js --limit=10

# 2. Test sur 100 images (DRY RUN)
node scripts/migrate-existing-images.js --limit=100

# 3. Si OK â†’ migration LIVE complÃ¨te
node scripts/migrate-existing-images.js --live
```

**âœ… RÃ©sultat attendu :**

- Migration sÃ©curisÃ©e (dry-run par dÃ©faut)
- Rapport JSON des erreurs
- Batch 10 + pause 2s

---

### A6.2 - Dashboard admin analytics

**ğŸ¯ Objectif :** Visualiser stats uploads (compression, erreurs)

**ğŸ“ Action :**

**CrÃ©er :** `src/components/features/admin/ImageAnalytics.jsx`

```jsx
// src/components/features/admin/ImageAnalytics.jsx
import { useEffect, useState } from 'react'
import { supabase } from '@/utils/supabaseClient'
import './ImageAnalytics.scss'

export default function ImageAnalytics() {
  const [stats, setStats] = useState(null)
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    async function fetchStats() {
      const { data, error } = await supabase.rpc('get_image_analytics_summary')

      if (error) {
        console.error('Erreur stats:', error)
      } else {
        setStats(data)
      }

      setLoading(false)
    }

    fetchStats()
  }, [])

  if (loading) {
    return <p>Chargement statistiques...</p>
  }

  if (!stats) {
    return <p>Erreur chargement statistiques</p>
  }

  return (
    <div className="image-analytics">
      <h2>Statistiques images (7 derniers jours)</h2>

      <div className="image-analytics__grid">
        <div className="stat-card">
          <h3>Uploads totaux</h3>
          <p className="stat-card__value">{stats.total_uploads}</p>
        </div>

        <div className="stat-card stat-card--success">
          <h3>SuccÃ¨s</h3>
          <p className="stat-card__value">{stats.success_count}</p>
        </div>

        <div className="stat-card stat-card--error">
          <h3>Ã‰checs</h3>
          <p className="stat-card__value">{stats.failed_count}</p>
        </div>

        <div className="stat-card">
          <h3>Compression moyenne</h3>
          <p className="stat-card__value">{stats.avg_compression_ratio}%</p>
        </div>

        <div className="stat-card">
          <h3>Temps conversion</h3>
          <p className="stat-card__value">{stats.avg_conversion_ms} ms</p>
        </div>

        <div className="stat-card">
          <h3>Temps upload</h3>
          <p className="stat-card__value">{stats.avg_upload_ms} ms</p>
        </div>

        <div className="stat-card stat-card--highlight">
          <h3>Stockage Ã©conomisÃ©</h3>
          <p className="stat-card__value">{stats.total_storage_saved_mb} MB</p>
        </div>
      </div>
    </div>
  )
}
```

**CrÃ©er :** `src/components/features/admin/ImageAnalytics.scss`

```scss
// src/components/features/admin/ImageAnalytics.scss
.image-analytics {
  padding: 2rem;

  h2 {
    margin-bottom: 1.5rem;
    color: var(--text-dark);
  }

  &__grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 1rem;
  }
}

.stat-card {
  background: var(--white);
  border-radius: 8px;
  padding: 1.5rem;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);

  h3 {
    font-size: 0.875rem;
    color: var(--text-muted);
    margin-bottom: 0.5rem;
    font-weight: 500;
  }

  &__value {
    font-size: 2rem;
    font-weight: 700;
    color: var(--text-dark);
    margin: 0;
  }

  &--success {
    border-left: 4px solid var(--pastel-green);
  }

  &--error {
    border-left: 4px solid var(--pastel-red);
  }

  &--highlight {
    background: linear-gradient(
      135deg,
      var(--pastel-blue-light),
      var(--pastel-green-light)
    );
  }
}
```

**âœ… RÃ©sultat attendu :**

- Dashboard analytics admin fonctionnel
- Stats temps rÃ©el (7 derniers jours)

---

## Ã‰TAPE A7 : TESTS & VALIDATION (2-3h)

### A7.1 - Tests E2E upload workflow

**ğŸ¯ Objectif :** Valider workflow complet (upload â†’ affichage â†’ cache)

**ğŸ“ Action :**

**CrÃ©er :** `tests/e2e/image-upload.spec.js`

```javascript
// tests/e2e/image-upload.spec.js
import { test, expect } from '@playwright/test'

test.describe('Upload image tÃ¢che (workflow complet)', () => {
  test.beforeEach(async ({ page }) => {
    // Login utilisateur test
    await page.goto('http://localhost:5173/login')
    await page.fill('[name="email"]', 'test@example.com')
    await page.fill('[name="password"]', 'TestPassword123!')
    await page.click('button[type="submit"]')
    await page.waitForURL('**/tableau')
  })

  test('Upload PNG â†’ conversion WebP â†’ affichage', async ({ page }) => {
    await page.goto('http://localhost:5173/edition')

    // Ouvrir modal ajout tÃ¢che
    await page.click('[data-testid="add-task-button"]')

    // Upload fichier PNG (50 KB)
    const fileInput = page.locator('input[type="file"]')
    await fileInput.setInputFiles('tests/fixtures/test-image.png')

    // VÃ©rifier progress indicator apparaÃ®t
    await expect(page.locator('.upload-progress')).toBeVisible()

    // Attendre fin upload (max 10s)
    await expect(page.locator('.upload-progress')).not.toBeVisible({
      timeout: 10000,
    })

    // VÃ©rifier tÃ¢che crÃ©Ã©e avec image
    const taskCard = page.locator('[data-testid="task-card"]').first()
    await expect(taskCard).toBeVisible()

    const taskImage = taskCard.locator('img')
    await expect(taskImage).toBeVisible()

    const src = await taskImage.getAttribute('src')

    // VÃ©rifier signed URL Supabase
    expect(src).toContain('supabase')
    expect(src).toContain('sign')
  })

  test('Upload SVG â†’ pas de conversion', async ({ page }) => {
    await page.goto('http://localhost:5173/edition')
    await page.click('[data-testid="add-task-button"]')

    const fileInput = page.locator('input[type="file"]')
    await fileInput.setInputFiles('tests/fixtures/icon.svg')

    await page.waitForSelector('[data-testid="task-card"]', { timeout: 10000 })

    const taskImage = page.locator('[data-testid="task-card"] img').first()
    const src = await taskImage.getAttribute('src')

    // VÃ©rifier extension SVG conservÃ©e
    expect(src).toContain('.svg')
  })

  test('Upload image identique â†’ dÃ©duplication', async ({ page }) => {
    // Upload 1Ã¨re fois
    await page.goto('http://localhost:5173/edition')
    await page.click('[data-testid="add-task-button"]')

    let fileInput = page.locator('input[type="file"]')
    await fileInput.setInputFiles('tests/fixtures/test-image.png')

    await expect(page.locator('.upload-progress')).not.toBeVisible({
      timeout: 10000,
    })

    const firstTaskPath = await page
      .locator('[data-testid="task-card"]')
      .first()
      .getAttribute('data-image-path')

    // Upload 2Ã¨me fois (mÃªme fichier)
    await page.click('[data-testid="add-task-button"]')

    fileInput = page.locator('input[type="file"]')
    await fileInput.setInputFiles('tests/fixtures/test-image.png')

    await expect(page.locator('.upload-progress')).not.toBeVisible({
      timeout: 10000,
    })

    const secondTaskPath = await page
      .locator('[data-testid="task-card"]')
      .nth(1)
      .getAttribute('data-image-path')

    // VÃ©rifier mÃªme path (dÃ©duplication)
    expect(firstTaskPath).toBe(secondTaskPath)
  })
})
```

**CrÃ©er fixtures :**

```bash
mkdir -p tests/fixtures

# Ajouter :
# - test-image.png (50 KB PNG)
# - icon.svg (2 KB SVG)
# - large-image.jpg (500 KB JPEG pour test quota)
```

**Commandes :**

```bash
yarn test:e2e
```

**âœ… RÃ©sultat attendu :**

- Tests E2E passent
- Workflow complet validÃ©

---

## Ã‰TAPE A8 : DOCUMENTATION & DÃ‰PLOIEMENT (1-2h)

### A8.1 - Mise Ã  jour CLAUDE.md

**ğŸ¯ Objectif :** Documenter nouveau systÃ¨me

**ğŸ“ Action :**

**Ajouter dans `CLAUDE.md` :**

````markdown
## SystÃ¨me d'images moderne (Phase A - Supabase Storage)

### Architecture

- **Images privÃ©es** : Supabase Storage (bucket `images`, signed URLs 24h)
- **Format** : WebP â‰¤ 20 KB (sauf SVG), support HEIC (iPhone)
- **Dimensions** : 192Ã—192px (mobile-first TSA)
- **Cache** : Service Worker (TTL 1h, placeholder SVG si offline)
- **DÃ©duplication** : SHA-256 hash (Ã©vite uploads identiques)
- **Versioning** : IncrÃ©mentÃ© Ã  chaque remplacement
- **Monitoring** : Table `image_metrics` (analytics compression, erreurs)

### Workflow upload (Phase A)

1. Validation MIME + magic bytes
2. Conversion HEIC â†’ JPEG (si iPhone)
3. Conversion â†’ WebP â‰¤ 20 KB (sauf SVG)
4. Calcul hash SHA-256 (dÃ©duplication)
5. VÃ©rification quota (RPC `check_image_quota`)
6. Upload Supabase Storage (retry automatique)
7. Enregistrement `user_assets` + `image_metrics`
8. GÃ©nÃ©ration signed URL (TTL 24h)
9. Cache Service Worker (affichage offline possible)

### Quotas (Phase A)

- **Free** : 5 tÃ¢ches + 2 rÃ©compenses = 7 images max
- **AbonnÃ©** : 40 tÃ¢ches + 10 rÃ©compenses = 50 images max
- **Admin/Staff** : IllimitÃ©
- **Stockage global** : 1 GB Supabase free tier

### Fichiers clÃ©s (Phase A)

- `src/utils/images/config.js` : Configuration globale
- `src/utils/images/heicConverter.js` : Support iPhone HEIC
- `src/utils/images/webpConverter.js` : Conversion WebP + hash
- `src/utils/images/imageValidator.js` : Validation unifiÃ©e
- `src/utils/storage/modernUploadImage.js` : Upload moderne complet
- `src/utils/upload/uploadWithRetry.js` : Retry automatique rÃ©seau
- `public/sw.js` : Service Worker cache offline
- `supabase/migrations/*_enhance_user_assets.sql` : Schema v2

### Commandes

```bash
# Migration images existantes (test)
node scripts/migrate-existing-images.js --limit=10

# Migration complÃ¨te (LIVE)
node scripts/migrate-existing-images.js --live

# Tests E2E upload
yarn test:e2e tests/e2e/image-upload.spec.js
```
````

### Phase B (Ã  venir)

- Images publiques â†’ Cloudinary CDN
- Edge Functions (delete Cloudinary, admin)
- Backup automatique (cron hebdomadaire)

````

**âœ… RÃ©sultat attendu :**
- Documentation complÃ¨te Ã  jour
- Guide migration + commandes

---

### A8.2 - Checklist prÃ©-dÃ©ploiement Phase A

**ğŸ“ VÃ©rifications :**

```markdown
## Checklist dÃ©ploiement Phase A

### Base de donnÃ©es
- [ ] Migration `enhance_user_assets` appliquÃ©e
- [ ] Migration `check_duplicate_image` appliquÃ©e
- [ ] Migration `image_metrics` appliquÃ©e
- [ ] Schema.sql Ã  jour (`yarn db:dump`)
- [ ] RPC functions testÃ©es

### Frontend
- [ ] Package `heic2any` installÃ©
- [ ] Tests unitaires passent (`yarn test`)
- [ ] Tests E2E passent (`yarn test:e2e`)
- [ ] Lint + format OK (`yarn check`)
- [ ] Build production OK (`yarn build`)

### Service Worker
- [ ] SW testÃ© en local (`yarn preview`)
- [ ] Cache fonctionne (DevTools â†’ Application â†’ Cache Storage)
- [ ] Placeholder SVG affichÃ© si offline

### Migration
- [ ] Script testÃ© sur 10 images (dry-run)
- [ ] Script testÃ© sur 100 images (dry-run)
- [ ] Rapport erreurs analysÃ©
- [ ] Migration LIVE planifiÃ©e

### Monitoring
- [ ] Dashboard admin accessible
- [ ] Metrics `image_metrics` loggÃ©es
- [ ] Alertes quotas testÃ©es

### Documentation
- [ ] CLAUDE.md mis Ã  jour
- [ ] README.md mis Ã  jour (si nÃ©cessaire)
- [ ] Changelog crÃ©Ã©
````

**âœ… RÃ©sultat attendu :**

- Phase A prÃªte au dÃ©ploiement
- Tous les tests passent
- Documentation complÃ¨te

---

# ğŸ“¦ PHASE B : IMAGES PUBLIQUES CLOUDINARY (OPTIONNEL)

**PrioritÃ© :** ğŸŸ¡ **APRÃˆS Phase A stabilisÃ©e**
**Temps estimÃ© :** 7-8 heures
**Objectif :** Extension pour images publiques partagÃ©es (cas rare : ~1% des images)

**Note :** Cette phase sera implÃ©mentÃ©e **APRÃˆS** la Phase A complÃ¨te et testÃ©e en production.

---

## Ã‰TAPE B1 : Configuration Cloudinary (1h)

### B1.1 - CrÃ©ation compte + configuration

**ğŸ“ Actions :**

1. CrÃ©er compte Cloudinary gratuit : https://cloudinary.com/users/register_free
2. CrÃ©er upload preset `appli-picto-public` :
   - Mode : `unsigned`
   - Transformations : `f_auto,q_auto:eco,w_192,h_192,c_fill`
   - Strip metadata : `true`

3. Ajouter variables `.env` :

```bash
VITE_CLOUDINARY_CLOUD_NAME=your_cloud_name
VITE_CLOUDINARY_UPLOAD_PRESET=appli-picto-public
VITE_CLOUDINARY_API_KEY=your_api_key
```

4. Ajouter variables `supabase/.env` (Edge Functions) :

```bash
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_api_key
CLOUDINARY_API_SECRET=your_api_secret
```

---

## Ã‰TAPE B2 : Migration BDD Cloudinary (30 min)

### B2.1 - Ajouter colonnes Cloudinary

**CrÃ©er :** `supabase/migrations/20251024000001_add_cloudinary_support.sql`

```sql
-- Ajout support Cloudinary dans user_assets

ALTER TABLE public.user_assets
  ADD COLUMN IF NOT EXISTS cloudinary_public_id TEXT,
  ADD COLUMN IF NOT EXISTS cloudinary_url TEXT,
  ADD COLUMN IF NOT EXISTS is_public BOOLEAN DEFAULT false NOT NULL;

-- Index
CREATE INDEX IF NOT EXISTS idx_user_assets_cloudinary
  ON public.user_assets(cloudinary_public_id)
  WHERE cloudinary_public_id IS NOT NULL;

-- Commentaires
COMMENT ON COLUMN public.user_assets.cloudinary_public_id IS
  'Public ID Cloudinary (si image publique partagÃ©e)';
COMMENT ON COLUMN public.user_assets.cloudinary_url IS
  'URL Cloudinary optimisÃ©e (si image publique)';
COMMENT ON COLUMN public.user_assets.is_public IS
  'true = Cloudinary (public), false = Supabase Storage (privÃ©)';
```

---

## Ã‰TAPE B3 : Service upload Cloudinary (2h)

### B3.1 - CrÃ©er service upload Cloudinary

**CrÃ©er :** `src/utils/cloudinary/uploadToCloudinary.js`

```javascript
// src/utils/cloudinary/uploadToCloudinary.js
import {
  CLOUDINARY_CLOUD_NAME,
  CLOUDINARY_UPLOAD_PRESET,
} from '@/utils/images/config'

export async function uploadToCloudinary(file, options = {}) {
  const { folder = 'pictos-public', tags = ['appli-picto'] } = options

  if (!CLOUDINARY_CLOUD_NAME || !CLOUDINARY_UPLOAD_PRESET) {
    throw new Error('Cloudinary non configurÃ©')
  }

  const formData = new FormData()
  formData.append('file', file)
  formData.append('upload_preset', CLOUDINARY_UPLOAD_PRESET)
  formData.append('folder', folder)
  formData.append('tags', tags.join(','))

  const response = await fetch(
    `https://api.cloudinary.com/v1_1/${CLOUDINARY_CLOUD_NAME}/image/upload`,
    {
      method: 'POST',
      body: formData,
    }
  )

  if (!response.ok) {
    const errorData = await response.json()
    throw new Error(errorData.error?.message || 'Upload Cloudinary Ã©chouÃ©')
  }

  const data = await response.json()

  return {
    url: data.secure_url,
    publicId: data.public_id,
    width: data.width,
    height: data.height,
    bytes: data.bytes,
    format: data.format,
  }
}
```

---

## Ã‰TAPE B4 : Edge Function delete Cloudinary (2h)

### B4.1 - CrÃ©er fonction sÃ©curisÃ©e

**CrÃ©er :** `supabase/functions/cloudinary-delete/index.ts`

```typescript
// supabase/functions/cloudinary-delete/index.ts
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

serve(async req => {
  const { publicId, userId } = await req.json()

  // VÃ©rifier ownership
  const supabaseClient = createClient(
    Deno.env.get('SUPABASE_URL') ?? '',
    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
  )

  const { data: asset } = await supabaseClient
    .from('user_assets')
    .select('id')
    .eq('cloudinary_public_id', publicId)
    .eq('user_id', userId)
    .single()

  if (!asset) {
    return new Response(JSON.stringify({ error: 'Unauthorized' }), {
      status: 403,
    })
  }

  // Supprimer sur Cloudinary (avec API secret)
  const timestamp = Math.round(Date.now() / 1000)
  const signature = await generateSignature(publicId, timestamp)

  const formData = new FormData()
  formData.append('public_id', publicId)
  formData.append('signature', signature)
  formData.append('api_key', Deno.env.get('CLOUDINARY_API_KEY')!)
  formData.append('timestamp', timestamp.toString())

  await fetch(
    `https://api.cloudinary.com/v1_1/${Deno.env.get('CLOUDINARY_CLOUD_NAME')}/image/destroy`,
    { method: 'POST', body: formData }
  )

  // Soft delete BDD
  await supabaseClient
    .from('user_assets')
    .update({ deleted_at: new Date().toISOString() })
    .eq('cloudinary_public_id', publicId)

  return new Response(JSON.stringify({ success: true }), {
    headers: { 'Content-Type': 'application/json' },
  })
})

async function generateSignature(
  publicId: string,
  timestamp: number
): Promise<string> {
  const stringToSign = `public_id=${publicId}&timestamp=${timestamp}${Deno.env.get('CLOUDINARY_API_SECRET')}`
  const encoder = new TextEncoder()
  const data = encoder.encode(stringToSign)
  const hashBuffer = await crypto.subtle.digest('SHA-1', data)
  const hashArray = Array.from(new Uint8Array(hashBuffer))
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
}
```

**DÃ©ployer :**

```bash
supabase functions deploy cloudinary-delete --no-verify-jwt
```

---

## Ã‰TAPE B5 : IntÃ©gration modernUploadImage (1h)

### B5.1 - Ã‰tendre pour support Cloudinary

**Modifier :** `src/utils/storage/modernUploadImage.js` (ajouter option `isPublic`)

```javascript
// Dans modernUploadImage()
const {
  userId,
  assetType = 'task_image',
  prefix = 'misc',
  isPublic = false, // ğŸ†• true â†’ Cloudinary, false â†’ Supabase
  onProgress = null,
} = options

// ... aprÃ¨s compression WebP

if (isPublic) {
  // Upload vers Cloudinary
  const uploadResult = await uploadToCloudinary(processedFile, {
    folder: 'pictos-public',
    tags: ['appli-picto', assetType],
  })

  // Enregistrer dans user_assets
  const { data: asset, error: dbError } = await supabase
    .from('user_assets')
    .insert({
      user_id: userId,
      asset_type: assetType,
      file_path: uploadResult.publicId,
      cloudinary_public_id: uploadResult.publicId,
      cloudinary_url: uploadResult.url,
      file_size: uploadResult.bytes,
      mime_type: `image/${uploadResult.format}`,
      width,
      height,
      sha256_hash: fileHash,
      is_public: true,
      version: 1,
    })
    .select('id')
    .single()

  if (dbError) throw dbError

  return {
    path: uploadResult.publicId,
    url: uploadResult.url,
    assetId: asset.id,
    width,
    height,
    error: null,
  }
} else {
  // Upload vers Supabase (code existant Phase A)
  // ...
}
```

---

## Ã‰TAPE B6 : Tests & documentation (1h)

### B6.1 - Tests Cloudinary

**CrÃ©er :** `tests/e2e/cloudinary-upload.spec.js`

```javascript
// tests/e2e/cloudinary-upload.spec.js
import { test, expect } from '@playwright/test'

test.describe('Upload Cloudinary (public)', () => {
  test('Upload image publique â†’ Cloudinary', async ({ page }) => {
    await page.goto('http://localhost:5173/admin/pictos-publics')

    const fileInput = page.locator('input[type="file"]')
    await fileInput.setInputFiles('tests/fixtures/test-image.png')

    await page.waitForSelector('[data-testid="picto-card"]', { timeout: 10000 })

    const pictoImage = page.locator('[data-testid="picto-card"] img').first()
    const src = await pictoImage.getAttribute('src')

    // VÃ©rifier URL Cloudinary
    expect(src).toContain('cloudinary.com')
    expect(src).toContain('res.cloudinary.com')
  })
})
```

### B6.2 - Documentation Phase B

**Ajouter dans `CLAUDE.md` :**

```markdown
## Phase B : Images publiques Cloudinary (optionnel)

### Architecture

- **Images publiques partagÃ©es** : Cloudinary CDN (cache 1 an)
- **Use case** : BibliothÃ¨que pictos partagÃ©s (rare, ~1% des images)
- **Transformations** : `f_auto,q_auto:eco,w_192,h_192,c_fill`

### Workflow upload public

1-4. Identique Phase A (validation, HEIC, WebP, hash) 5. VÃ©rification quota 6. **Upload Cloudinary** (au lieu de Supabase) 7. Enregistrement `user_assets` (is_public=true) 8. URL Cloudinary retournÃ©e directement (pas de signed URL)

### Fichiers clÃ©s Phase B

- `src/utils/cloudinary/uploadToCloudinary.js` : Upload public
- `supabase/functions/cloudinary-delete/index.ts` : Delete sÃ©curisÃ©
- `src/utils/storage/modernUploadImage.js` : Support `isPublic` option
```

---

# ğŸ“Š RÃ‰SUMÃ‰ EXÃ‰CUTIF

## Temps total par phase

| Phase       | Description                             | Temps estimÃ© |
| ----------- | --------------------------------------- | ------------ |
| **Phase A** | Images privÃ©es Supabase (complet)       | **18-22h**   |
| **Phase B** | Images publiques Cloudinary (optionnel) | **7-8h**     |
| **TOTAL**   | SystÃ¨me complet                         | **25-30h**   |

## Ordre d'exÃ©cution recommandÃ©

### ğŸ”´ PRIORITÃ‰ 1 : Phase A complÃ¨te (18-22h)

1. **A1** - BDD (2-3h) : Migrations + RPC + metrics
2. **A2** - Frontend utils (3-4h) : HEIC + WebP + validation
3. **A3** - Upload service (4-5h) : Pipeline complet + retry
4. **A4** - Service Worker (3-4h) : Cache offline + placeholder
5. **A5** - IntÃ©gration (2-3h) : Hooks + composants
6. **A6** - Migration (2-3h) : Script + monitoring
7. **A7** - Tests (2-3h) : E2E + validation
8. **A8** - Docs (1-2h) : CLAUDE.md + checklist

### ğŸŸ¡ PRIORITÃ‰ 2 : Phase B (APRÃˆS Phase A stabilisÃ©e)

9. **B1-B6** - Cloudinary (7-8h) : Extension images publiques

---

## Prochaine Ã©tape

**ğŸš€ Commencer par Ã‰TAPE A1.1 : Migration BDD `enhance_user_assets`**

**Question :** Es-tu prÃªt Ã  dÃ©marrer l'implÃ©mentation de l'Ã©tape A1.1 ? Je vais te guider pas Ã  pas pour chaque Ã©tape. ğŸ¯
